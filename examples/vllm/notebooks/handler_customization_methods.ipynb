{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Handler Customization Methods - Complete Guide\n",
    "\n",
    "This notebook demonstrates **all three methods** for customizing `/ping` and `/invocations` handlers in vLLM on SageMaker.\n",
    "\n",
    "## Three Methods Overview\n",
    "\n",
    "### Method 1: Environment Variables (Highest Priority)\n",
    "- **File**: `handlers_env_var.py`\n",
    "- **How**: Point to handler functions via environment variables\n",
    "- **Env Vars**: `CUSTOM_FASTAPI_PING_HANDLER`, `CUSTOM_FASTAPI_INVOCATION_HANDLER`\n",
    "- **Use When**: You need explicit control and want to override all other methods\n",
    "\n",
    "### Method 2: Decorators\n",
    "- **File**: `handlers_decorator.py`\n",
    "- **How**: Use `@custom_ping_handler` and `@custom_invocation_handler` decorators\n",
    "- **Env Vars**: Only `CUSTOM_SCRIPT_FILENAME` needed\n",
    "- **Use When**: You want clean, explicit handler registration (recommended)\n",
    "\n",
    "### Method 3: Function Discovery (Lowest Priority)\n",
    "- **File**: `handlers_discovery.py`\n",
    "- **How**: Name functions `custom_sagemaker_ping_handler`, `custom_sagemaker_invocation_handler`\n",
    "- **Env Vars**: Only `CUSTOM_SCRIPT_FILENAME` needed\n",
    "- **Use When**: You want the simplest approach with convention over configuration\n",
    "\n",
    "## Handler Resolution Priority\n",
    "```\n",
    "1. Environment Variables (Method 1) ‚Üê Highest priority\n",
    "2. Decorator Registration (Method 2)\n",
    "3. Function Discovery (Method 3)\n",
    "4. Framework Defaults ‚Üê Lowest priority\n",
    "```\n",
    "\n",
    "## Choose Your Method\n",
    "Set the `METHOD` variable below to test different approaches:\n",
    "- `\"env_var\"` - Environment Variables\n",
    "- `\"decorator\"` - Decorators (recommended)\n",
    "- `\"discovery\"` - Function Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "config",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected method: discovery\n",
      "\n",
      "You can change this and re-run the notebook to test different methods!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION: Choose your handler customization method\n",
    "# ============================================================\n",
    "\n",
    "METHOD = \"discovery\"  # Options: \"env-var\", \"decorator\", \"discovery\"\n",
    "\n",
    "print(f\"Selected method: {METHOD}\")\n",
    "print(\"\\nYou can change this and re-run the notebook to test different methods!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "imports",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "clients",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "runtime_client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sts_client = boto3.client('sts', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "names",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "model_name = f'vllm-{METHOD}-{timestamp}'\n",
    "endpoint_config_name = f'vllm-{METHOD}-config-{timestamp}'\n",
    "endpoint_name = f'vllm-{METHOD}-endpoint-{timestamp}'\n",
    "account_id = sts_client.get_caller_identity()['Account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "params",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Method: discovery\n",
      "  Model Name: vllm-discovery-20251127-015140\n",
      "  Endpoint Name: vllm-discovery-endpoint-20251127-015140\n",
      "  HuggingFace Model: meta-llama/Meta-Llama-3-8B-Instruct\n",
      "  Instance Type: ml.g6.4xlarge\n",
      "  S3 Bucket: sheteng-demo\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PARAMETERS - Update these for your environment\n",
    "# ============================================================\n",
    "\n",
    "# Container image\n",
    "# Make sure this exists!!!!!\n",
    "container_image = f'{account_id}.dkr.ecr.{region}.amazonaws.com/vllm:0.11.2-sagemaker-v1.2'\n",
    "\n",
    "# HuggingFace model\n",
    "huggingface_model_id = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "huggingface_token = 'hf_your_token_here'  # Replace with your token\n",
    "\n",
    "# Instance configuration\n",
    "instance_type = 'ml.g6.4xlarge'\n",
    "execution_role = f'arn:aws:iam::{account_id}:role/SageMakerExecutionRole'\n",
    "\n",
    "# S3 configuration\n",
    "s3_bucket = 'sheteng-demo'  # Replace with your bucket\n",
    "s3_key_prefix = f'vllm-handlers/{METHOD}/{timestamp}'\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Method: {METHOD}\")\n",
    "print(f\"  Model Name: {model_name}\")\n",
    "print(f\"  Endpoint Name: {endpoint_name}\")\n",
    "print(f\"  HuggingFace Model: {huggingface_model_id}\")\n",
    "print(f\"  Instance Type: {instance_type}\")\n",
    "print(f\"  S3 Bucket: {s3_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "method-config",
   "metadata": {},
   "source": [
    "## Method-Specific Configuration\n",
    "\n",
    "Based on your selected method, we'll configure the appropriate handler file and environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "method-setup",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Method 3: Function Discovery\n",
      "  Handler file: handlers_discovery.py\n",
      "  Handlers discovered by function names:\n",
      "    - custom_sagemaker_ping_handler\n",
      "    - custom_sagemaker_invocation_handler\n",
      "\n",
      "üìÑ Handler file location: ../model_artifacts_examples/handlers_discovery.py\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Configure handler file and environment based on method\n",
    "# ============================================================\n",
    "\n",
    "# Map method to handler file\n",
    "handler_files = {\n",
    "    \"env-var\": \"handlers_env_var.py\",\n",
    "    \"decorator\": \"handlers_decorator.py\",\n",
    "    \"discovery\": \"handlers_discovery.py\"\n",
    "}\n",
    "\n",
    "handler_filename = handler_files[METHOD]\n",
    "handler_filepath = Path(\"../model_artifacts_examples\") / handler_filename\n",
    "\n",
    "# Base environment variables (common to all methods)\n",
    "environment = {\n",
    "    \"SM_VLLM_MODEL\": huggingface_model_id,\n",
    "    \"HUGGING_FACE_HUB_TOKEN\": huggingface_token,\n",
    "    \"SM_VLLM_MAX_MODEL_LEN\": \"2048\",\n",
    "    \"CUSTOM_SCRIPT_FILENAME\": handler_filename,\n",
    "    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"DEBUG\",\n",
    "}\n",
    "\n",
    "# Method-specific environment variables\n",
    "if METHOD == \"env-var\":\n",
    "    # Method 1: Explicitly point to handler functions\n",
    "    environment[\"CUSTOM_FASTAPI_PING_HANDLER\"] = f\"{handler_filename}:health_check\"\n",
    "    environment[\"CUSTOM_FASTAPI_INVOCATION_HANDLER\"] = f\"{handler_filename}:inference\"\n",
    "    print(f\"‚úì Method 1: Environment Variables\")\n",
    "    print(f\"  Handler file: {handler_filename}\")\n",
    "    print(f\"  Ping handler: {environment['CUSTOM_FASTAPI_PING_HANDLER']}\")\n",
    "    print(f\"  Invocation handler: {environment['CUSTOM_FASTAPI_INVOCATION_HANDLER']}\")\n",
    "\n",
    "elif METHOD == \"decorator\":\n",
    "    # Method 2: Decorators handle registration automatically\n",
    "    print(f\"‚úì Method 2: Decorators\")\n",
    "    print(f\"  Handler file: {handler_filename}\")\n",
    "    print(f\"  Handlers registered via @custom_ping_handler and @custom_invocation_handler\")\n",
    "\n",
    "elif METHOD == \"discovery\":\n",
    "    # Method 3: Function names follow convention\n",
    "    print(f\"‚úì Method 3: Function Discovery\")\n",
    "    print(f\"  Handler file: {handler_filename}\")\n",
    "    print(f\"  Handlers discovered by function names:\")\n",
    "    print(f\"    - custom_sagemaker_ping_handler\")\n",
    "    print(f\"    - custom_sagemaker_invocation_handler\")\n",
    "\n",
    "print(f\"\\nüìÑ Handler file location: {handler_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "upload-s3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚òÅÔ∏è  Uploading handlers_discovery.py to S3...\n",
      "‚úì Uploaded to: s3://sheteng-demo/vllm-handlers/discovery/20251127-015140/handlers_discovery.py\n",
      "  Model data S3 prefix: s3://sheteng-demo/vllm-handlers/discovery/20251127-015140/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Upload handler file to S3\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n‚òÅÔ∏è  Uploading {handler_filename} to S3...\")\n",
    "\n",
    "s3_key = f\"{s3_key_prefix}/{handler_filename}\"\n",
    "s3_client.upload_file(str(handler_filepath), s3_bucket, s3_key)\n",
    "\n",
    "model_data_s3_prefix = f\"s3://{s3_bucket}/{s3_key_prefix}/\"\n",
    "\n",
    "print(f\"‚úì Uploaded to: s3://{s3_bucket}/{s3_key}\")\n",
    "print(f\"  Model data S3 prefix: {model_data_s3_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "create-model",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating SageMaker model: vllm-discovery-20251127-015140\n",
      "‚úì Model created\n",
      "  Model ARN: arn:aws:sagemaker:us-west-2:875423407011:model/vllm-discovery-20251127-015140\n",
      "  Method: discovery\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create SageMaker Model\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nüîß Creating SageMaker model: {model_name}\")\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=execution_role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": container_image,\n",
    "        \"ModelDataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3Uri\": model_data_s3_prefix,\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"CompressionType\": \"None\",\n",
    "            }\n",
    "        },\n",
    "        \"Environment\": environment,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"‚úì Model created\")\n",
    "print(f\"  Model ARN: {create_model_response['ModelArn']}\")\n",
    "print(f\"  Method: {METHOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "create-endpoint-config",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è  Creating endpoint configuration: vllm-discovery-config-20251127-015140\n",
      "‚úì Endpoint configuration created\n",
      "  Config ARN: arn:aws:sagemaker:us-west-2:875423407011:endpoint-config/vllm-discovery-config-20251127-015140\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create Endpoint Configuration\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Creating endpoint configuration: {endpoint_config_name}\")\n",
    "\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1.0,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"‚úì Endpoint configuration created\")\n",
    "print(f\"  Config ARN: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "create-endpoint",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Creating endpoint: vllm-discovery-endpoint-20251127-015140\n",
      "‚è±Ô∏è  This will take approximately 5-10 minutes...\n",
      "\n",
      "üí° Monitor: https://console.aws.amazon.com/sagemaker/home?region=us-west-2#/endpoints/vllm-discovery-endpoint-20251127-015140\n",
      "\n",
      "‚úì Endpoint creation initiated\n",
      "  Endpoint ARN: arn:aws:sagemaker:us-west-2:875423407011:endpoint/vllm-discovery-endpoint-20251127-015140\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create Endpoint\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nüöÄ Creating endpoint: {endpoint_name}\")\n",
    "print(\"‚è±Ô∏è  This will take approximately 5-10 minutes...\")\n",
    "print(f\"\\nüí° Monitor: https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\\n\")\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(f\"‚úì Endpoint creation initiated\")\n",
    "print(f\"  Endpoint ARN: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "wait-endpoint",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Waiting for endpoint to be in service...\n",
      "(This may take 5-10 minutes)\n",
      "\n",
      "‚úì Endpoint is in service!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Wait for Endpoint\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n‚è≥ Waiting for endpoint to be in service...\")\n",
    "print(\"(This may take 5-10 minutes)\\n\")\n",
    "\n",
    "waiter = sagemaker_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={\"Delay\": 20, \"MaxAttempts\": 60}\n",
    ")\n",
    "\n",
    "print(\"‚úì Endpoint is in service!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing",
   "metadata": {},
   "source": [
    "## Testing the Custom Handlers\n",
    "\n",
    "Now let's test the custom handlers. The response will include a `method` field showing which customization method was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "test-basic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Test 1: Basic Inference (Method: discovery)\n",
      "Prompt: What is the capital of Amazon?\n",
      "\n",
      "‚úì Response received:\n",
      "  Method: function_discovery\n",
      "  Model: vllm\n",
      "  Prediction:  The answer is that Amazon doesn't have a traditional capital city. The company is headquartered in Seattle, Washington, USA, and has multiple offices...\n",
      "  Tokens: {'prompt_tokens': 8, 'completion_tokens': 100, 'total_tokens': 108}\n",
      "\n",
      "Full response:\n",
      "{\n",
      "  \"predictions\": [\n",
      "    \" The answer is that Amazon doesn't have a traditional capital city. The company is headquartered in Seattle, Washington, USA, and has multiple offices and facilities around the world.\\n\\nHowever, Amazon has built several research and development centers, called \\\"Amazon Lab126,\\\" in various locations, including:\\n1. Palo Alto, California, USA\\n2. Cambridge, Massachusetts, USA\\n3. Sunnyvale, California, USA\\n4. Shenzhen, Guangdong, China\\n5. Bengaluru, Karnataka,\"\n",
      "  ],\n",
      "  \"model\": \"vllm\",\n",
      "  \"method\": \"function_discovery\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"completion_tokens\": 100,\n",
      "    \"total_tokens\": 108\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Test 1: Basic Inference\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nü§ñ Test 1: Basic Inference (Method: {METHOD})\")\n",
    "\n",
    "request_body = {\n",
    "    \"prompt\": \"What is the capital of Amazon?\",\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "print(f\"Prompt: {request_body['prompt']}\")\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(request_body),\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "\n",
    "print(f\"\\n‚úì Response received:\")\n",
    "print(f\"  Method: {result.get('method', 'N/A')}\")\n",
    "print(f\"  Model: {result.get('model', 'N/A')}\")\n",
    "if \"predictions\" in result:\n",
    "    print(f\"  Prediction: {result['predictions'][0][:150]}...\")\n",
    "if \"usage\" in result:\n",
    "    print(f\"  Tokens: {result['usage']}\")\n",
    "\n",
    "print(f\"\\nFull response:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "test-error",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Test 2: Error Handling (Method: discovery)\n",
      "Sending request without 'prompt' field...\n",
      "\n",
      "‚úì Error caught by client:\n",
      "  An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\": \"Missing required field: prompt\"}\". See https://us-west-2.con\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Test 2: Error Handling\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nü§ñ Test 2: Error Handling (Method: {METHOD})\")\n",
    "\n",
    "request_body_invalid = {\n",
    "    \"max_tokens\": 50,\n",
    "    # Missing \"prompt\" field\n",
    "}\n",
    "\n",
    "print(\"Sending request without 'prompt' field...\")\n",
    "\n",
    "try:\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(request_body_invalid),\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"\\n‚úì Error handled correctly:\")\n",
    "        print(f\"  Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Expected error but got:\")\n",
    "        print(json.dumps(result, indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úì Error caught by client:\")\n",
    "    print(f\"  {str(e)[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cleanup",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANUP: DELETING RESOURCES\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è  This will delete all resources and stop charges\n",
      "\n",
      "Deleting endpoint: vllm-discovery-endpoint-20251127-015140\n",
      "  ‚úì Endpoint deletion initiated\n",
      "  Waiting for endpoint to be deleted...\n",
      "  ‚úì Endpoint deleted\n",
      "\n",
      "Deleting endpoint configuration: vllm-discovery-config-20251127-015140\n",
      "  ‚úì Endpoint configuration deleted\n",
      "\n",
      "Deleting model: vllm-discovery-20251127-015140\n",
      "  ‚úì Model deleted\n",
      "\n",
      "============================================================\n",
      "‚úÖ CLEANUP COMPLETE\n",
      "============================================================\n",
      "All resources deleted:\n",
      "  ‚úì Endpoint: vllm-discovery-endpoint-20251127-015140\n",
      "  ‚úì Endpoint Config: vllm-discovery-config-20251127-015140\n",
      "  ‚úì Model: vllm-discovery-20251127-015140\n",
      "\n",
      "‚úì No ongoing charges!\n",
      "\n",
      "Note: S3 artifacts remain at s3://sheteng-demo/vllm-handlers/discovery/20251127-015140/\n",
      "      Delete manually if no longer needed\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cleanup - Delete All Resources\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANUP: DELETING RESOURCES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚ö†Ô∏è  This will delete all resources and stop charges\\n\")\n",
    "\n",
    "# Delete endpoint\n",
    "print(f\"Deleting endpoint: {endpoint_name}\")\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "print(\"  ‚úì Endpoint deletion initiated\")\n",
    "\n",
    "# Wait for endpoint deletion\n",
    "print(\"  Waiting for endpoint to be deleted...\")\n",
    "waiter = sagemaker_client.get_waiter(\"endpoint_deleted\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "print(\"  ‚úì Endpoint deleted\")\n",
    "\n",
    "# Delete endpoint configuration\n",
    "print(f\"\\nDeleting endpoint configuration: {endpoint_config_name}\")\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "print(\"  ‚úì Endpoint configuration deleted\")\n",
    "\n",
    "# Delete model\n",
    "print(f\"\\nDeleting model: {model_name}\")\n",
    "sagemaker_client.delete_model(ModelName=model_name)\n",
    "print(\"  ‚úì Model deleted\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ CLEANUP COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"All resources deleted:\")\n",
    "print(f\"  ‚úì Endpoint: {endpoint_name}\")\n",
    "print(f\"  ‚úì Endpoint Config: {endpoint_config_name}\")\n",
    "print(f\"  ‚úì Model: {model_name}\")\n",
    "print(f\"\\n‚úì No ongoing charges!\")\n",
    "print(f\"\\nNote: S3 artifacts remain at s3://{s3_bucket}/{s3_key_prefix}/\")\n",
    "print(f\"      Delete manually if no longer needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1658fc-5c70-4063-9539-e092e16c5d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
